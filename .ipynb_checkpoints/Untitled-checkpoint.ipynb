{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class data_preprocessing():\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.datasetf = './dataset'\n",
    "        self.outputf = './outputs'\n",
    "        self.path = os.path.join(self.datasetf,filename)\n",
    "        self.dataset = pd.read_csv(self.path)\n",
    "\n",
    "    def merge_states(self):\n",
    "        datafr = self.dataset\n",
    "        new_dict = []\n",
    "        for country in self.unique:\n",
    "            c_data = datafr[datafr['Country/Region'] == country].sum(axis=0)\n",
    "            new_dict.append(c_data)\n",
    "        d = pd.DataFrame(new_dict)\n",
    "        d = d.drop(['Province/State', 'Country/Region', 'Lat', 'Long'], axis = 1)\n",
    "        unique = pd.DataFrame(self.unique, columns = ['Country'])\n",
    "        dataset = pd.concat([unique, d], axis = 1)\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def re_dimension_testing(self):\n",
    "        filepath = './dataset/testing.csv'\n",
    "        d = pd.read_csv(filepath)\n",
    "        unique = d['location'].unique()\n",
    "        dicts = []\n",
    "        for country in unique:\n",
    "            count = d[d['location'] == country].count()[2]\n",
    "            new_dict = { 'Country' : country, 'Counts' : count}\n",
    "            dicts.append(new_dict)\n",
    "        data = pd.DataFrame(dicts)\n",
    "        slicer = data[data['Counts'] == data['Counts'].max()]\n",
    "        cols = d[d['location'] == slicer.iloc[0][0]]['date'].to_list()\n",
    "        reframe = pd.DataFrame(columns = [cols])\n",
    "        n=0\n",
    "        for country in unique:\n",
    "            zeros = len(cols) - d[d['location'] == country]['date'].count()\n",
    "            testing = d[d['location'] == country]['new_tests']\n",
    "            row = []\n",
    "            for x in range(0,zeros):\n",
    "                row.append(0)\n",
    "            row.extend(testing)\n",
    "            reframe.loc[n] = row\n",
    "            n = n + 1\n",
    "        unique = pd.DataFrame(unique, columns = ['Country'])\n",
    "        reframe = pd.concat([unique,reframe], axis = 1)\n",
    "        cols.insert(0, \"Country\")\n",
    "        reframe.columns = [cols]\n",
    "        reframe.fillna(0, inplace=True)\n",
    "        self.dataset = reframe\n",
    "        \n",
    "    def consistent_countries_t(self):\n",
    "        dataset = pd.read_csv('./outputs/testing.csv')\n",
    "        unique = pd.DataFrame(self.unique)\n",
    "        unique.columns = ['Country']\n",
    "        df3 = pd.merge(unique, dataset, on='Country', how = 'left')\n",
    "        df3.fillna(0, inplace=True)\n",
    "        self.dataset = df3\n",
    "        \n",
    "    def consistent_countries(self):\n",
    "        dataFr = self.dataset\n",
    "        unique = pd.DataFrame(self.unique)\n",
    "        unique.columns = ['Country']\n",
    "        df3 = pd.merge(unique, dataFr, on='Country', how = 'left')\n",
    "        self.dataset = df3 \n",
    "        \n",
    "    def consistent_dates(self):\n",
    "        data = self.dataset\n",
    "        data.iloc[:,((self.row-1)*-1):-1]\n",
    "        data.iloc[:,0]\n",
    "        tes = pd.concat([data.iloc[:,0], data.iloc[:,((self.row-1)*-1):-1]], axis=1)\n",
    "        self.dataset = tes\n",
    "\n",
    "    def save_file(self):\n",
    "        save_path = os.path.join(self.outputf,self.filename)\n",
    "        dataset = pd.DataFrame(self.dataset)\n",
    "        dataset.to_csv(save_path, index=False)\n",
    "        \n",
    "    @classmethod\n",
    "    def time_rows(cls, datasetf):\n",
    "        files = os.listdir(datasetf)\n",
    "        row = []\n",
    "        for file in files:\n",
    "            dat = pd.read_csv(os.path.join(datasetf, file))\n",
    "            row.append(dat.shape[1])\n",
    "        data_preprocessing.row = np.array(row)[0] - 3\n",
    "        \n",
    "    @classmethod\n",
    "    def unique_countries(cls, datasetf):\n",
    "        lst = os.listdir(datasetf)\n",
    "        arr = []\n",
    "        for file in lst:\n",
    "            arr.append(pd.read_csv(os.path.join(datasetf,file)).shape[0])\n",
    "        result = {'File' : lst , 'Counts': arr}\n",
    "        result = pd.DataFrame(result)\n",
    "        file = result[result['Counts'] == result['Counts'].min()].iloc[0][0]\n",
    "        unique = pd.read_csv(os.path.join(datasetf,file))['Country/Region'].unique()\n",
    "        data_preprocessing.unique = unique\n",
    "\n",
    "\n",
    "files = ['confirmed.csv' , 'death.csv', 'recovery.csv']\n",
    "for file in files:\n",
    "    const = data_preprocessing(file)\n",
    "    const.time_rows(const.datasetf)\n",
    "    const.unique_countries(const.datasetf)\n",
    "    const.merge_states()\n",
    "    const.consistent_countries()\n",
    "    const.consistent_dates()\n",
    "    const.save_file()\n",
    "\n",
    "const2 = data_preprocessing('testing.csv')\n",
    "const2.time_rows(const2.datasetf)\n",
    "const2.unique_countries(const2.datasetf)\n",
    "const2.re_dimension_testing()\n",
    "const2.save_file()\n",
    "const2.consistent_countries_t()\n",
    "const2.consistent_dates()\n",
    "const2.save_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class restructuring():\n",
    "    def __init__(self, output_folder):\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "    def Plotly_style(self):\n",
    "        # Fetching list of all files in output folder\n",
    "        lst = os.listdir(self.output_folder)\n",
    "        # Creating a dataframe for confirmed cases\n",
    "        dfc_path = os.path.join(self.output_folder,lst[0])\n",
    "        dfc = pd.read_csv(dfc_path)\n",
    "        # Creating a dataframe for deaths\n",
    "        dfd_path = os.path.join(self.output_folder,lst[1])\n",
    "        dfd = pd.read_csv(dfd_path)\n",
    "        # Creating a dataframe for recovery\n",
    "        dfr_path = os.path.join(self.output_folder, lst[2])\n",
    "        dfr = pd.read_csv(dfr_path)\n",
    "        # Creating a dataframe for testing\n",
    "        dft_path = os.path.join(self.output_folder, lst[3])\n",
    "        dft = pd.read_csv(dft_path)\n",
    "        # Creating an empty dataframe\n",
    "        restruct = pd.DataFrame()\n",
    "        # Declaring country\n",
    "        unique = dfc['Country'].unique()\n",
    "        for country in unique:\n",
    "            # Generating slicers\n",
    "            rowC = dfc[dfc['Country'] == country].drop(columns = 'Country')\n",
    "            rowD = dfd[dfd['Country'] == country].drop(columns = 'Country')\n",
    "            rowR = dfr[dfr['Country'] == country].drop(columns = 'Country')\n",
    "            rowT = dft[dft['Country'] == country].drop(columns = 'Country')\n",
    "            count = rowT.shape[1]\n",
    "            rowN = [country for i in range(count)] \n",
    "            # Creating a new dataframe\n",
    "            c = pd.DataFrame(rowC.T)\n",
    "            d = pd.DataFrame(rowD.T)\n",
    "            r = pd.DataFrame(rowR.T)\n",
    "            t = pd.DataFrame(rowT.T)\n",
    "            t.set_index(rowC.columns, inplace=True)\n",
    "            date = pd.DataFrame(rowC.columns)\n",
    "            date.set_index(rowC.columns, inplace=True)\n",
    "            n = pd.DataFrame(rowN)\n",
    "            n = n.set_index(rowC.columns)\n",
    "            data = pd.concat([n, date, c, d, r, t], axis=1)\n",
    "            data.columns = ['Country', 'Date', 'Confirmed', 'Deaths', 'Recovery', 'Testing']\n",
    "            restruct = pd.concat([restruct, data], axis=0)\n",
    "            restruct.to_csv(os.path.join(self.output_folder, 'unified.csv'), index=False)\n",
    "\n",
    "unified = restructuring('./outputs')\n",
    "unified.Plotly_style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = pd.read_csv('./outputs/unified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Date</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Recovery</th>\n",
       "      <th>Testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1/22/20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1/23/20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1/24/20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1/25/20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1/26/20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19256</th>\n",
       "      <td>Tajikistan</td>\n",
       "      <td>4/29/20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19257</th>\n",
       "      <td>Tajikistan</td>\n",
       "      <td>4/30/20</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19258</th>\n",
       "      <td>Tajikistan</td>\n",
       "      <td>5/1/20</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19259</th>\n",
       "      <td>Tajikistan</td>\n",
       "      <td>5/2/20</td>\n",
       "      <td>76</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19260</th>\n",
       "      <td>Tajikistan</td>\n",
       "      <td>5/3/20</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19261 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Country     Date  Confirmed  Deaths  Recovery  Testing\n",
       "0      Afghanistan  1/22/20          0       0         0      0.0\n",
       "1      Afghanistan  1/23/20          0       0         0      0.0\n",
       "2      Afghanistan  1/24/20          0       0         0      0.0\n",
       "3      Afghanistan  1/25/20          0       0         0      0.0\n",
       "4      Afghanistan  1/26/20          0       0         0      0.0\n",
       "...            ...      ...        ...     ...       ...      ...\n",
       "19256   Tajikistan  4/29/20          0       0         0      0.0\n",
       "19257   Tajikistan  4/30/20         15       0         0      0.0\n",
       "19258   Tajikistan   5/1/20         15       0         0      0.0\n",
       "19259   Tajikistan   5/2/20         76       2         0      0.0\n",
       "19260   Tajikistan   5/3/20        128       2         0      0.0\n",
       "\n",
       "[19261 rows x 6 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Covid19",
   "language": "python",
   "name": "covid19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
