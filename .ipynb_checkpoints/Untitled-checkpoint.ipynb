{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete\n"
     ]
    }
   ],
   "source": [
    "# Making necessary imports\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Declaring a dictioray with links to confirmed, recovered and deaths datasets\n",
    "urls = {\n",
    "    'confirmed' : \"https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_confirmed_global.csv&filename=time_series_covid19_confirmed_global.csv'\",\n",
    "    'recovery' : \"https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_recovered_global.csv&filename=time_series_covid19_recovered_global.csv\",\n",
    "    'death' : \"https://data.humdata.org/hxlproxy/api/data-preview.csv?url=https%3A%2F%2Fraw.githubusercontent.com%2FCSSEGISandData%2FCOVID-19%2Fmaster%2Fcsse_covid_19_data%2Fcsse_covid_19_time_series%2Ftime_series_covid19_deaths_global.csv&filename=time_series_covid19_deaths_global.csv\",\n",
    "    'testing' : \"https://covid.ourworldindata.org/data/owid-covid-data.xlsx\"\n",
    "}\n",
    "\n",
    "# Making a function that can download and save the dataset\n",
    "save_link = \"C:\\\\Users\\\\usama\\\\OneDrive\\\\Desktop\\\\github\\\\COVID19-visualization\\\\dataset\\\\\"  #path to dataset folder\n",
    "def download_files(url):\n",
    "    dlink = requests.get(urls[url])\n",
    "    fname = url + \".csv\"\n",
    "    data = open(os.path.join(save_link, fname), 'wb').write(dlink.content)\n",
    "\n",
    "# Running a for loop to download all files\n",
    "for url in urls:\n",
    "    download_files(url)\n",
    "\n",
    "# Coverting \"Testing\" file from xls to csv\n",
    "testing_xls = pd.read_excel('./dataset/testing.csv', 'Sheet1', dtype=str, index_col=None)\n",
    "testing_xls.to_csv('./dataset/testing.csv', encoding='utf-8', index=False)\n",
    "#data_xls.to_csv('csvfile.csv', encoding='utf-8', index=False)\n",
    "\n",
    "print('Download complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.read_csv(\"./dataset/testing.csv\")\n",
    "unique = testing['location'].unique()\n",
    "\n",
    "dicts = []\n",
    "\n",
    "for country in unique:\n",
    "    count = testing[testing['location'] == country].count()[2]\n",
    "    new_dict = { 'Country' : country, 'Counts' : count}\n",
    "    dicts.append(new_dict)\n",
    "    \n",
    "data = pd.DataFrame(dicts)\n",
    "slicer = data[data['Counts'] == data['Counts'].max()]\n",
    "cols = testing[testing['location'] == slicer.iloc[0][0]]['date'].to_list()\n",
    "\n",
    "reframe = pd.DataFrame(columns = [cols])\n",
    "\n",
    "n=0\n",
    "for country in unique:\n",
    "    zeros = len(cols) - testing[testing['location'] == country]['date'].count()\n",
    "    test = testing[testing['location'] == country]['new_tests']\n",
    "    row = []\n",
    "    for x in range(0,zeros):\n",
    "        row.append(0)\n",
    "    row.extend(test)\n",
    "    reframe.loc[n] = row\n",
    "    n = n + 1\n",
    "    \n",
    "unique = pd.DataFrame(unique, columns = ['Country'])\n",
    "reframe = pd.concat([unique,reframe], axis = 1)\n",
    "cols.insert(0, \"Country\")\n",
    "reframe.columns = [cols]\n",
    "reframe.fillna(0, inplace=True)\n",
    "reframe.to_csv('./outputs/testing_all.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['confirmed.csv', 'death.csv', 'recovery.csv', 'testing.csv']"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_countries(lst):\n",
    "    arr = []\n",
    "    \n",
    "    for file in lst:\n",
    "        arr.append(pd.read_csv(os.path.join('./outputs',file)).shape[0])\n",
    "        \n",
    "    result = {'File' : lst , 'Counts': arr}\n",
    "    result = pd.DataFrame(result)\n",
    "    file = result[result['Counts'] == result['Counts'].min()].iloc[0][0]\n",
    "    unique = pd.read_csv(os.path.join('./outputs',file))['Country']\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                Afghanistan\n",
       "1                    Albania\n",
       "2                    Algeria\n",
       "3                    Andorra\n",
       "4                     Angola\n",
       "               ...          \n",
       "182           Western Sahara\n",
       "183    Sao Tome and Principe\n",
       "184                    Yemen\n",
       "185                  Comoros\n",
       "186               Tajikistan\n",
       "Name: Country, Length: 187, dtype: object"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = unique_countries(os.listdir('./outputs'))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consistency(unique, fnames):\n",
    "    for file in fnames:\n",
    "        dataF = pd.read_csv(os.path.join('./outputs',file))\n",
    "        n_dataset = pd.DataFrame()\n",
    "        for country in unique:\n",
    "            sli = da[da['Country'] == country]\n",
    "            n_dataset = pd.concat([n_dataset, sli], axis=0)\n",
    "        n_dataset.to_csv('./all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency(a, os.listdir('./outputs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rows():\n",
    "    files = os.listdir('./outputs')\n",
    "    row = []\n",
    "    for file in files:\n",
    "        dat = pd.read_csv(os.path.join('./outputs',file))\n",
    "        row.append(dat.shape[1])\n",
    "    return np.array(row).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./outputs/testing_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-104"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((rows()-1)*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,((rows()-1)*-1):-1]\n",
    "data.iloc[:,0]\n",
    "tes = pd.concat([data.iloc[:,0], data.iloc[:,((rows()-1)*-1):-1]], axis=1)\n",
    "tes.to_csv('./ref_testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'dataset' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-560-b77f601b15e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mpd1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_preprocessing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'confirmed.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mpd1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mpd1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-560-b77f601b15e2>\u001b[0m in \u001b[0;36mmerge_states\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Province/State'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Country/Region'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Lat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Long'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0munique\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Country'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'dataset' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "class data_preprocessing():\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.path = os.path.join('./dataset',filename)\n",
    "\n",
    "    def merge_states(self):\n",
    "        datafr = pd.read_csv(self.path)\n",
    "        unique = datafr['Country/Region'].unique()\n",
    "        new_dict = []\n",
    "        for country in unique:\n",
    "            c_data = datafr[datafr['Country/Region'] == country].sum(axis=0)\n",
    "            new_dict.append(c_data)\n",
    "        d = pd.DataFrame(new_dict)\n",
    "        d = d.drop(['Province/State', 'Country/Region', 'Lat', 'Long'], axis = 1)\n",
    "        unique = pd.DataFrame(unique, columns = ['Country'])\n",
    "        dataset = pd.concat([unique, d], axis = 1)\n",
    "        self.dataset = dataset\n",
    "\n",
    "pd1 = data_preprocessing('confirmed.csv')\n",
    "pd1.merge_states()\n",
    "pd1.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Covid19",
   "language": "python",
   "name": "covid19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
