{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import country_converter as coco\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class data_preprocessing():\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.datasetf = './dataset'\n",
    "        self.outputf = './outputs'\n",
    "        self.path = os.path.join(self.datasetf,filename)\n",
    "        self.dataset = pd.read_csv(self.path)\n",
    "\n",
    "    def merge_states(self):\n",
    "        datafr = self.dataset\n",
    "        new_dict = []\n",
    "        for country in self.unique:\n",
    "            c_data = datafr[datafr['Country/Region'] == country].sum(axis=0)\n",
    "            new_dict.append(c_data)\n",
    "        d = pd.DataFrame(new_dict)\n",
    "        d = d.drop(['Province/State', 'Country/Region', 'Lat', 'Long'], axis = 1)\n",
    "        unique = pd.DataFrame(self.unique, columns = ['Country'])\n",
    "        dataset = pd.concat([unique, d], axis = 1)\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def re_dimension_testing(self):\n",
    "        filepath = './dataset/testing.csv'\n",
    "        d = pd.read_csv(filepath)\n",
    "        unique = d['location'].unique()\n",
    "        dicts = []\n",
    "        for country in unique:\n",
    "            count = d[d['location'] == country].count()[2]\n",
    "            new_dict = { 'Country' : country, 'Counts' : count}\n",
    "            dicts.append(new_dict)\n",
    "        data = pd.DataFrame(dicts)\n",
    "        slicer = data[data['Counts'] == data['Counts'].max()]\n",
    "        cols = d[d['location'] == slicer.iloc[0][0]]['date'].to_list()\n",
    "        reframe = pd.DataFrame(columns = [cols])\n",
    "        n=0\n",
    "        for country in unique:\n",
    "            zeros = len(cols) - d[d['location'] == country]['date'].count()\n",
    "            testing = d[d['location'] == country]['new_tests']\n",
    "            row = []\n",
    "            for x in range(0,zeros):\n",
    "                row.append(0)\n",
    "            row.extend(testing)\n",
    "            reframe.loc[n] = row\n",
    "            n = n + 1\n",
    "        unique = pd.DataFrame(unique, columns = ['Country'])\n",
    "        reframe = pd.concat([unique,reframe], axis = 1)\n",
    "        cols.insert(0, \"Country\")\n",
    "        reframe.columns = [cols]\n",
    "        reframe.fillna(0, inplace=True)\n",
    "        self.dataset = reframe\n",
    "        \n",
    "    def consistent_countries_t(self):\n",
    "        dataset = pd.read_csv('./outputs/testing.csv')\n",
    "        unique = pd.DataFrame(self.unique)\n",
    "        unique.columns = ['Country']\n",
    "        df3 = pd.merge(unique, dataset, on='Country', how = 'left')\n",
    "        df3.fillna(0, inplace=True)\n",
    "        self.dataset = df3\n",
    "        \n",
    "    def consistent_countries(self):\n",
    "        dataFr = self.dataset\n",
    "        unique = pd.DataFrame(self.unique)\n",
    "        unique.columns = ['Country']\n",
    "        df3 = pd.merge(unique, dataFr, on='Country', how = 'left')\n",
    "        self.dataset = df3 \n",
    "        \n",
    "    def consistent_dates(self):\n",
    "        data = self.dataset\n",
    "        data.iloc[:,((self.row-1)*-1):-1]\n",
    "        data.iloc[:,0]\n",
    "        tes = pd.concat([data.iloc[:,0], data.iloc[:,((self.row-1)*-1):-1]], axis=1)\n",
    "        self.dataset = tes\n",
    "\n",
    "    def save_file(self):\n",
    "        save_path = os.path.join(self.outputf,self.filename)\n",
    "        dataset = pd.DataFrame(self.dataset)\n",
    "        dataset.to_csv(save_path, index=False)\n",
    "        \n",
    "    @classmethod\n",
    "    def time_rows(cls, datasetf):\n",
    "        files = os.listdir(datasetf)\n",
    "        row = []\n",
    "        for file in files:\n",
    "            dat = pd.read_csv(os.path.join(datasetf, file))\n",
    "            row.append(dat.shape[1])\n",
    "        data_preprocessing.row = np.array(row)[0] - 3\n",
    "        \n",
    "    @classmethod\n",
    "    def unique_countries(cls, datasetf):\n",
    "        lst = os.listdir(datasetf)\n",
    "        arr = []\n",
    "        for file in lst:\n",
    "            arr.append(pd.read_csv(os.path.join(datasetf,file)).shape[0])\n",
    "        result = {'File' : lst , 'Counts': arr}\n",
    "        result = pd.DataFrame(result)\n",
    "        file = result[result['Counts'] == result['Counts'].min()].iloc[0][0]\n",
    "        unique = pd.read_csv(os.path.join(datasetf,file))['Country/Region'].unique()\n",
    "        data_preprocessing.unique = unique\n",
    "\n",
    "\n",
    "files = ['confirmed.csv' , 'death.csv', 'recovery.csv']\n",
    "for file in files:\n",
    "    const = data_preprocessing(file)\n",
    "    const.time_rows(const.datasetf)\n",
    "    const.unique_countries(const.datasetf)\n",
    "    const.merge_states()\n",
    "    const.consistent_countries()\n",
    "    const.consistent_dates()\n",
    "    const.save_file()\n",
    "\n",
    "const2 = data_preprocessing('testing.csv')\n",
    "const2.time_rows(const2.datasetf)\n",
    "const2.unique_countries(const2.datasetf)\n",
    "const2.re_dimension_testing()\n",
    "const2.save_file()\n",
    "const2.consistent_countries_t()\n",
    "const2.consistent_dates()\n",
    "const2.save_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Diamond Princess not found in regex\n",
      "WARNING:root:MS Zaandam not found in regex\n"
     ]
    }
   ],
   "source": [
    "class restructuring():\n",
    "    def __init__(self, output_folder):\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "    def Plotly_style(self):\n",
    "        # Fetching list of all files in output folder\n",
    "        lst = os.listdir(self.output_folder)\n",
    "        # Creating a dataframe for confirmed cases\n",
    "        dfc_path = os.path.join(self.output_folder,lst[0])\n",
    "        dfc = pd.read_csv(dfc_path)\n",
    "        # Creating a dataframe for deaths\n",
    "        dfd_path = os.path.join(self.output_folder,lst[1])\n",
    "        dfd = pd.read_csv(dfd_path)\n",
    "        # Creating a dataframe for recovery\n",
    "        dfr_path = os.path.join(self.output_folder, lst[2])\n",
    "        dfr = pd.read_csv(dfr_path)\n",
    "        # Creating a dataframe for testing\n",
    "        dft_path = os.path.join(self.output_folder, lst[3])\n",
    "        dft = pd.read_csv(dft_path)\n",
    "        # Creating an empty dataframe\n",
    "        restruct = pd.DataFrame()\n",
    "        # Declaring country\n",
    "        unique = dfc['Country'].unique()\n",
    "        for country in unique:\n",
    "            # Generating slicers\n",
    "            rowC = dfc[dfc['Country'] == country].drop(columns = 'Country')\n",
    "            rowD = dfd[dfd['Country'] == country].drop(columns = 'Country')\n",
    "            rowR = dfr[dfr['Country'] == country].drop(columns = 'Country')\n",
    "            rowT = dft[dft['Country'] == country].drop(columns = 'Country')\n",
    "            count = rowT.shape[1]\n",
    "            geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "            location = geolocator.geocode(country, timeout=20)\n",
    "            rowLat = [location.latitude for i in range(count)]\n",
    "            rowLong = [location.longitude for i in range(count)]\n",
    "            rowN = [country for i in range(count)] \n",
    "            Con = coco.convert(names=country, to='continent')\n",
    "            rowCon = [Con for i in range(count)]\n",
    "            rowTS = []\n",
    "            ls = rowT.T\n",
    "            ls.columns = ['Confirmed']\n",
    "            ls = ls['Confirmed'].tolist()\n",
    "            rowTS.insert(0, ls[0])\n",
    "            for x in range(1,len(ls)):\n",
    "                ans = rowTS[x-1] + ls[x]\n",
    "                rowTS.append(ans)    \n",
    "            rowDc = np.arange(len(ls))\n",
    "            # Creating a new dataframe\n",
    "            lat = pd.DataFrame(rowLat)\n",
    "            lat.set_index(rowC.columns, inplace=True)\n",
    "            long = pd.DataFrame(rowLong)\n",
    "            long.set_index(rowC.columns, inplace=True)\n",
    "            c = pd.DataFrame(rowC.T)\n",
    "            d = pd.DataFrame(rowD.T)\n",
    "            dc = pd.DataFrame(rowDc)\n",
    "            dc.set_index(rowC.columns, inplace=True)\n",
    "            r = pd.DataFrame(rowR.T)\n",
    "            ts = pd.DataFrame(rowTS)\n",
    "            ts.set_index(rowC.columns, inplace=True)\n",
    "            if ts.sum()[0] == 0:\n",
    "                ts = c\n",
    "            else:\n",
    "                ts = ts\n",
    "            t = pd.DataFrame(rowT.T)\n",
    "            t.set_index(rowC.columns, inplace=True)\n",
    "            cons = pd.DataFrame(rowCon)\n",
    "            cons.set_index(rowC.columns, inplace=True)\n",
    "            date = pd.DataFrame(rowC.columns)\n",
    "            date.set_index(rowC.columns, inplace=True)\n",
    "            n = pd.DataFrame(rowN)\n",
    "            n = n.set_index(rowC.columns)\n",
    "            data = pd.concat([n, cons, lat, long, dc, date, c, d, r, t, ts], axis=1)\n",
    "            data.columns = ['Country', 'Continent','Lat', 'Long', 'Day Count', 'Date', 'Confirmed', 'Deaths', 'Recovery', 'dTesting', 'Testing']\n",
    "            restruct = pd.concat([restruct, data], axis=0)\n",
    "        restruct.to_csv(os.path.join(self.output_folder, 'unified.csv'), index=False)\n",
    "\n",
    "unified = restructuring('./outputs')\n",
    "unified.Plotly_style()\n",
    "\n",
    "uni = pd.read_csv('./outputs/unified.csv')\n",
    "uni['Continent'] = uni['Continent'].replace('not found', 'Cruise Ship')\n",
    "uni.to_csv('./outputs/unified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = pd.read_csv('./outputs/unified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni['Continent'] = uni['Continent'].replace('not found', 'Cruise Ship')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni.to_csv('./outputs/unified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go # or plotly.express as px\n",
    "import plotly.express as px\n",
    "df = pd.read_csv('./outputs/unified.csv')\n",
    "fig = go.Figure(\n",
    "    px.scatter(df, x=\"Testing\", y=\"Confirmed\", animation_frame=\"Date\", animation_group=\"Country\",\n",
    "           size=\"Deaths\", color=\"Continent\", hover_name=\"Country\",\n",
    "              log_x=True, log_y= True, size_max=80, range_x=[1000,10000000], range_y=[10,15000000],\n",
    "              template='ggplot2', title=\"Covid-19: Spread of Virus\")\n",
    ") # or any Plotly Express function e.g. px.bar(...)\n",
    "# fig.add_trace( ... )\n",
    "# fig.update_layout( ... )\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "\n",
    "app = dash.Dash()\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(figure=fig)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on http://127.0.0.1:8050/\n",
      "Running on http://127.0.0.1:8050/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Running on http://127.0.0.1:8050/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugger PIN: 445-233-265\n",
      "Debugger PIN: 445-233-265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Debugger PIN: 445-233-265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "app.run_server(debug=True, use_reloader=False)  # Turn off reloader if inside Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.000074 104.999927\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "location = geolocator.geocode(\"China\")\n",
    "print(location.latitude, location.longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Covid19",
   "language": "python",
   "name": "covid19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
